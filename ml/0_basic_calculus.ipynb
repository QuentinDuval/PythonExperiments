{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Differentials, Gradients, Level Curves, Hessian, Jacobians\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Optimization with equality constraints\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Optimization with one constraint\n",
    "\n",
    "Consider minimizing / maximizing the function $f(x)$ constraint to $g(x) = 0$. The critical points $x_0$ we are looking for are the ones where $\\nabla f(x_0) = \\lambda \\nabla g(x_0)$ with $\\lambda \\ne 0$.\n",
    "\n",
    "> **Proof:** Consider the level curves of $f(x) = c$. At a critical point $x_0$, this level curve must be tangent to the level curve $g(x) = 0$, or otherwise we could move along the curve $g(x) = 0$ to find a better value for $f$. The tangent of a level curve is the gradient of the function, and so $\\nabla f$ must be colinear to $\\nabla g$.\n",
    "\n",
    "We can therefore create a function $\\mathcal{L}$ for Lagrangian, that combines $f$ and $g$ such that its critical points encapsulate the optimization objective:\n",
    "\n",
    "&emsp; $\\mathcal{L}(x,\\lambda) = f(x) - \\lambda g(x)$\n",
    "&emsp; ,\n",
    "&emsp; $\\nabla_x \\mathcal{L} = 0 \\implies \\nabla f(x) = \\lambda \\nabla g(x)$\n",
    "&emsp; and \n",
    "&emsp; $\\displaystyle \\frac{\\partial \\mathcal{L}}{\\partial \\lambda} = 0 \\implies g(x) = 0$\n",
    "\n",
    "Searching for the critical points of the langrangian will give us potential solutions to our problem (we still have to check for their values to check if they are valid maximum of minimums)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Optimization with multiple constraints\n",
    "\n",
    "Consider minimizing / maximizing the function $f(x)$ constraint to $g_1(x) = 0, \\dots g_n(x) = 0$. The critical points $x_0$ we are looking for are the ones where $\\nabla f(x_0) = \\lambda_1 \\nabla g_1(x_0) + \\dots + \\lambda_n \\nabla g_n(x)$ such that $\\exists i, \\lambda_i \\ne 0$.\n",
    "\n",
    "Similarly as above, we can build a lagrangian and look for its critical points in order to solve the constraint problem:\n",
    "\n",
    "&emsp; $\\mathcal{L}(x,\\lambda) = f(x) - \\sum_i \\lambda_i g_i(x)$\n",
    "&emsp; such that\n",
    "&emsp; $\\exists i, \\lambda_i \\ne 0$\n",
    "\n",
    "**Proof:** Consider the $G(x) = 0$, where $G(x) = (g_1(x), \\dots g_n(x))$ is a manifold because the $g_i$ are smooth. Again, if $f(x_0)$ changes along a neighboring point of $G(x_0)$, then $x_0$ cannot be a critical point, or otherwise we could move along $G$ to find a better spot.\n",
    "\n",
    "The normal of the plan along $G$ at point $x_0$ is equal to the Jacobian $J(G)$ of $G$. Any vector $x$ that is in the plan, that is perpendicular to $J(G)$, must be so that $\\nabla f$ along that vector $x$ is null:\n",
    "\n",
    "&emsp; $J(G) = \\begin{pmatrix} \\nabla g_1 \\\\ \\vdots \\\\ \\nabla g_n \\end{pmatrix}$\n",
    "&emsp;\n",
    "&emsp; $x J(G) = 0 \\implies x^T \\nabla f = 0$\n",
    "\n",
    "This means that the kernel (null space) of $J(G)$ is contained in the kernel of $\\nabla f$. And so the space spanned by $\\nabla f$ is contained into the space spanned by $J(G)$. This means that the row $\\nabla f$ is expressible as a linear combination of the row space of $J(G)$: $\\nabla f = \\sum_n \\lambda_i \\nabla g_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Example: deriving properties through Lagrangian\n",
    "\n",
    "Lagrangians and Lagrange multipliers ($\\lambda_i$) can be used to solve optimization problems in closed forms. They can also be used to derive some interesting properties between quantities.\n",
    "\n",
    "For instance, say we have a covariance matrix $S$ and we are looking for directions, that is unit vectors $v$ (the constraint is on the norm) such that the quantity $v^T S v$ is maximized (such that the variance in that direction is maximized). We can build a Lagrangian for this:\n",
    "\n",
    "&emsp; $\\mathcal{L}(x,\\lambda) = x^T S x - \\lambda ( x^T x - 1 )$\n",
    "&emsp; and\n",
    "&emsp; $\\nabla_x \\mathcal{L} = 0$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $S x = \\lambda x$\n",
    "\n",
    "We therefore show that vectors that satisfy this are eigen vectors of the covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Optimization with inequality constraints\n",
    "---\n",
    "\n",
    "When things are not symmetric (minimizing is not the same as maximizing) anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Maximization with one inequality constraint\n",
    "\n",
    "Consider **maximizing** the function $f(x)$ constraint to $g(x) \\ge 0$. The critical points $x_0$ are such that:\n",
    "\n",
    "* $\\nabla f(x_0) = - \\lambda \\nabla g(x_0)$ with $\\lambda \\ge 0$\n",
    "* $\\lambda \\ne 0$ if and only if $g(x_0) = 0$\n",
    "\n",
    "We can therefore create a function $\\mathcal{L}$ for Lagrangian, that combines $f$ and $g$ such that its critical points encapsulate the optimization objective:\n",
    "\n",
    "&emsp; $\\boxed{\\mathcal{L}(x,\\lambda) = f(x) + \\lambda g(x)}$ with $\\lambda \\ge 0$\n",
    "\n",
    "**Proof:** For $g(x_0) = 0$, consider the level curves of $f(x) = c$. At a critical point $x_0$, this level curve must be tangent to the level curve $g(x) = 0$, but must also be such that $\\nabla f$ point toward the forbidden region, i.e $g(x) < 0$, toward the descending $g$. It means that $\\nabla f$ must be colinear and point to the other direction of $\\nabla g$.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Minimization with one inequality constraint\n",
    "\n",
    "Consider **minimizing** the function $f(x)$ constraint to $g(x) \\ge 0$. The critical points $x_0$ are such that:\n",
    "\n",
    "* $\\nabla f(x_0) = \\lambda \\nabla g(x_0)$ with $\\lambda \\ge 0$\n",
    "* $\\lambda \\ne 0$ if and only if $g(x_0) = 0$\n",
    "\n",
    "We can therefore create a function $\\mathcal{L}$ for Lagrangian, that combines $f$ and $g$ such that its critical points encapsulate the optimization objective:\n",
    "\n",
    "&emsp; $\\boxed{\\mathcal{L}(x,\\lambda) = f(x) - \\lambda g(x)}$ with $\\lambda \\ge 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### General case (multiple constraints of different types)\n",
    "\n",
    "To **maximize** the function $f(x)$ subject to the constraints $g_i(x) = 0$ and $h_j(x) \\ge 0$, find the critical points of the Lagrangian:\n",
    "\n",
    "&emsp; $\\mathcal{L}(x,\\lambda,\\mu) = f(x) + \\sum_i \\lambda_i g_i(x) + \\sum_i \\mu_i h_i(x)$\n",
    "&emsp; with\n",
    "&emsp; $\\lambda_i \\ne 0$\n",
    "&emsp; and\n",
    "&emsp; $\\mu_j \\ge 0$\n",
    "\n",
    "To **minimize** the function $f(x)$ subject to the constraints $g_i(x) = 0$ and $h_j(x) \\ge 0$, find the critical points of the Lagrangian:\n",
    "\n",
    "&emsp; $\\mathcal{L}(x,\\lambda,\\mu) = f(x) - \\sum_i \\lambda_i g_i(x) - \\sum_i \\mu_i h_i(x)$\n",
    "&emsp; with\n",
    "&emsp; $\\lambda_i \\ne 0$\n",
    "&emsp; and\n",
    "&emsp; $\\mu_j \\ge 0$\n",
    "\n",
    "**The simple mnemonic is + for maximization and - for minimization** and make the constraints on the factors positive when dealing with inequality constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

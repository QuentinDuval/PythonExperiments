{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The basis for a framework of automatic differentiation such as PyTorch.\n",
    "\n",
    "What we want is to:\n",
    "1. Build a forward pass manually, passing tensors / variable through blocks\n",
    "2. Make sure each variable remember which block uses it (to get its gradients)\n",
    "\"\"\"\n",
    "\n",
    "import abc\n",
    "import functools\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import operator\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-b388b8ef53f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-511fcf5d529e>\u001b[0m in \u001b[0;36mmultiply\u001b[1;34m(v1, v2)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient_fcts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMultiplyFct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient_fcts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMultiplyFct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "class Variable:\n",
    "    def __init__(self, value, from_op=None):\n",
    "        self.value = value\n",
    "        self.gradient = None\n",
    "        self.from_op = from_op\n",
    "        self.gradient_fcts = []\n",
    "    \n",
    "    def compute_gradient(self):\n",
    "        self.gradient = sum(fct.derivative_by(self) for fct in self.gradient_fcts) if self.gradient_fcts else 1\n",
    "        return self.gradient\n",
    "    \n",
    "    def backward(self):\n",
    "        # TODO - in need for a graph to do a kind of topological sort?\n",
    "        pass\n",
    "\n",
    "    \n",
    "class Function(abc.ABC):\n",
    "    # TODO - make it a metaclass\n",
    "    # TODO - you could make it a Monad in Haskell\n",
    "    \n",
    "    def __init__(self, arguments: List[Variable]):\n",
    "        self.arguments = arguments\n",
    "        self.output = None\n",
    "    \n",
    "    def __call__(self) -> Variable:\n",
    "        result = self.apply(arg.value for arg in self.arguments)\n",
    "        self.output = Variable(result, self)\n",
    "        for arg in self.arguments:\n",
    "            arg.gradient_fcts.append(self)\n",
    "        return self.output\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def apply(self, argument_values) -> Variable:\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def derivative_by(self, by: Variable) -> float:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "class AddFct(Function):\n",
    "    def __init__(self, arguments):\n",
    "        super().__init__(arguments)\n",
    "    \n",
    "    def apply(self, argument_values):\n",
    "        return functools.reduce(operator.add, argument_values, 0)\n",
    "    \n",
    "    def derivative_by(self, x: Variable):\n",
    "        if x in self.arguments:\n",
    "            return self.output.gradient\n",
    "        return 0\n",
    "\n",
    "\n",
    "class MultiplyFct(Function):\n",
    "    def __init__(self, arguments):\n",
    "        super().__init__(arguments)\n",
    "    \n",
    "    def apply(self, argument_values):\n",
    "        return functools.reduce(operator.mult, argument_values, 1)\n",
    "    \n",
    "    def derivative_by(self, x: Variable):\n",
    "        total = 1.\n",
    "        for arg in self.arguments:\n",
    "            if arg != x:\n",
    "                total *= arg.value\n",
    "        return total\n",
    "    \n",
    "    \n",
    "def add(v1: Variable, v2: Variable):\n",
    "    op = AddFct([v1, v2])\n",
    "    return op()\n",
    "\n",
    "\n",
    "def add(v1: Variable, v2: Variable):\n",
    "    op = AddFct([v1, v2])\n",
    "    return op()\n",
    "\n",
    "\n",
    "x1 = Variable(1)\n",
    "x2 = Variable(2)\n",
    "x3 = Variable(3)\n",
    "y1 = add(x1, x2)\n",
    "y2 = add(x2, x3)\n",
    "z = multiply(y1, y2)\n",
    "print(z.compute_gradient())\n",
    "print(y1.compute_gradient())\n",
    "print(y2.compute_gradient())\n",
    "print(x1.compute_gradient())\n",
    "print(x2.compute_gradient())\n",
    "print(x3.compute_gradient())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.]], requires_grad=True)\n",
      "tensor([[1.]], grad_fn=<ExpBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.zeros((1, 1), requires_grad=True)\n",
    "print(x)\n",
    "y = torch.exp(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

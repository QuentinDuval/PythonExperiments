{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to force the reload of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# In order to make the import of local modules\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import abc\n",
    "from collections import *\n",
    "from dataclasses import dataclass\n",
    "import enum\n",
    "import gym\n",
    "import heapq\n",
    "import numpy as np\n",
    "from typing import *\n",
    "\n",
    "from ml.rl.core import *\n",
    "\n",
    "%matplotlib inline\n",
    "import imageio\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation shape: (2,)\n",
      "action space: {0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Showing information about the environment\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with gym.make(\"MountainCar-v0\") as env:\n",
    "    print(\"observation shape:\", env.reset().shape)\n",
    "    print(\"action space:\", {env.action_space.sample() for _ in range(100)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_agent(agent: Agent):\n",
    "    with gym.make(\"MountainCar-v0\") as env:\n",
    "        total_reward = 0.0\n",
    "        obs = env.reset()\n",
    "        env.render()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.get_action(env, obs)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            env.render()\n",
    "        print(\"Total reward {0:.2f}\".format(total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward -200.00\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Random agent\n",
    "\"\"\"\n",
    "\n",
    "class RandomAgent(Agent):\n",
    "    def get_action(self, env, state):\n",
    "        return env.action_space.sample()\n",
    "\n",
    "\n",
    "try_agent(RandomAgent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: -200.0\n",
      "Mean score: -200.0\n",
      "Mean score: -200.0\n",
      "Mean score: -200.0\n",
      "Mean score: -200.0\n",
      "Mean score: -200.0\n",
      "Mean score: -200.0\n",
      "Mean score: -200.0\n",
      "Mean score: -200.0\n",
      "Mean score: -200.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cross Entropy Method:\n",
    "- Start with a random policy\n",
    "- Play N episodes with the current policy\n",
    "- Take the episodes above a reward boundary (typically percentile 70th)\n",
    "- Train on these \"Elite\" episodes (throw away the uninteresting ones)\n",
    "=> Look like a kind of genetic algorithm stuff\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from ml.rl.cross_entropy_method import *\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Implementation of a policy to learn via a Neural Net\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    def __init__(self, observation_size, hidden_size, action_size):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(observation_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, action_size))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, observations, with_softmax = False):\n",
    "        ys = self.fc(observations)\n",
    "        if with_softmax:\n",
    "            return self.softmax(ys)\n",
    "        return ys\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Test with the policy of a neural net\n",
    "\n",
    "=> Note it will NEVER PROGRESS since random policy does not produce a working example to learn from\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "fc_net = FullyConnectedNet(observation_size=2, hidden_size=100, action_size=3)\n",
    "policy = NeuralNetPolicy(iteration_nb=5, learning_rate=0.1, net=fc_net)\n",
    "agent = CrossEntropyAgent(policy)\n",
    "with gym.make(\"MountainCar-v0\") as env:\n",
    "    scores = agent.fit(env, max_iteration=10, batch_size=16, batch_threshold=0.7)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 50 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 100 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 150 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 200 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 250 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 300 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 350 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 400 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 450 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 500 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 550 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 600 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 650 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 700 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 750 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 800 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 850 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 900 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 950 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1000 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1050 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1100 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1150 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1200 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1250 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1300 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1350 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1400 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1450 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1500 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1550 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1600 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1650 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1700 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1750 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1800 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1850 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1900 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 1950 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2000 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2050 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2100 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2150 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2200 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2250 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2300 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2350 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2400 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2450 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2500 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2550 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2600 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2650 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2700 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2750 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2800 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2850 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2900 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 2950 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3000 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3050 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3100 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3150 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3200 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3250 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3300 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3350 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3400 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3450 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3500 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3550 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3600 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3650 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3700 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3750 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3800 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3850 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3900 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 3950 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4000 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4050 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4100 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4150 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4200 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4250 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4300 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4350 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4400 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4450 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4500 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4550 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4600 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4650 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4700 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4750 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4800 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4850 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4900 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 4950 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5000 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5050 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5100 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5150 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5200 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5250 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5300 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5350 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5400 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5450 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5500 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5550 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5600 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5650 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5700 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5750 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5800 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5850 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5900 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 5950 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6000 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6050 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6100 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6150 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6200 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6250 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6300 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6350 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6400 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6450 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6500 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6550 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6600 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6650 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6700 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6750 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6800 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6850 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6900 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 6950 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7000 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7050 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7100 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7150 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7200 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7250 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7300 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7350 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7400 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7450 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7500 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7550 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7600 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7650 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7700 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7750 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7800 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7850 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7900 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 7950 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 8000 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 8050 Mean score: -200.0 (epsilon: 0.3 )\n",
      "# 8100 Mean score: -200.0 (epsilon: 0.3 )\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-53917a57156b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m                        \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                        \u001b[0mpolicy_improvement_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                        epsilon_decrease_factor = 0.99)\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Perso\\PythonExperiments\\ml\\rl\\deep_q_learning.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, env, is_success, max_episodes, replay_buffer_size, replay_start_size, batch_size, policy_improvement_size, epsilon_decrease_factor)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepisode_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_episodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0mepisode_experiences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisode_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_play_episode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[0mexperiences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisode_experiences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisode_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Perso\\PythonExperiments\\ml\\rl\\deep_q_learning.py\u001b[0m in \u001b[0;36m_play_episode\u001b[1;34m(self, env)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mexperiences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mExperience\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Perso\\PythonExperiments\\ml\\rl\\deep_q_learning.py\u001b[0m in \u001b[0;36mget_action\u001b[1;34m(self, env, state)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     def fit(self, env,\n",
      "\u001b[1;32mD:\\Perso\\PythonExperiments\\ml\\rl\\deep_q_learning.py\u001b[0m in \u001b[0;36mbest_action\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-53917a57156b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, observations)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1024\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "With Deep Q-Learning\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from ml.rl.deep_q_learning import *\n",
    "\n",
    "\n",
    "class RegressionNet(nn.Module):\n",
    "    def __init__(self, observation_size, hidden_size, action_size):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(observation_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, action_size))\n",
    "\n",
    "    def forward(self, observations):\n",
    "        ys = self.fc(observations)\n",
    "        return ys\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "Try the Deep Q learning agent\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "start_epsilon = 0.3\n",
    "end_epsilon = 0.1\n",
    "\n",
    "policy_net=RegressionNet(2, 200, 3)\n",
    "\n",
    "agent = DeepQLearningAgent(\n",
    "    q_values=NeuralNetQValues(net=policy_net, iteration_nb=10, learning_rate=1e-3),\n",
    "    start_epsilon=start_epsilon,\n",
    "    min_epsilon=end_epsilon)\n",
    "\n",
    "with gym.make(\"MountainCar-v0\") as env:\n",
    "    max_iterations = 100\n",
    "    scores = agent.fit(env,\n",
    "                       is_success = lambda score: score > -200,\n",
    "                       max_episodes = 10_000,\n",
    "                       replay_buffer_size = 100,\n",
    "                       replay_start_size = 100,\n",
    "                       batch_size = 16,\n",
    "                       policy_improvement_size = 50,\n",
    "                       epsilon_decrease_factor = 0.99)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "from collections import *\n",
    "from dataclasses import dataclass\n",
    "import enum\n",
    "import gym\n",
    "import numpy as np\n",
    "from typing import *\n",
    "\n",
    "%matplotlib inline\n",
    "import imageio\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pyglet\n",
    "from pyglet.gl import *\n",
    "\n",
    "window = pyglet.window.Window(width=300, height=200, display=None)\n",
    "window.clear()\n",
    "\n",
    "from gym.envs.classic_control import rendering\n",
    "viewer = rendering.Viewer(screen_width, screen_height)\n",
    "'''\n",
    "\n",
    "# TODO - complexe... first without the maze, find the place to go\n",
    "\n",
    "# TODO - move through a maze where 1 are blocked, 0 are free, and you must find the end\n",
    "# TODO - use convolution net to find the right decision\n",
    "# TODO - reward is -1 for each time your are in the maze\n",
    "\n",
    "# TODO - make a custom space for actions / states?\n",
    "\n",
    "\n",
    "class MazeEnv(gym.Env):\n",
    "    def __init__(self, maze: np.ndarray, start_pos: Tuple[int, int]):\n",
    "        self.maze: np.ndarray = np.array(maze)\n",
    "        self.start_pos: Tuple[int, int] = start_pos\n",
    "        self.end_positions: Set[Tuple[int, int]] = self._find_end_positions(maze)\n",
    "        self.state = None # Must be immutable? I guess so\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        self.observation_space = gym.spaces.MultiDiscrete(list(maze.shape))\n",
    "    \n",
    "    @property\n",
    "    def done(self) -> bool:\n",
    "        return self.state in self.end_positions\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = self.start_pos\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, action):\n",
    "        if self.done:\n",
    "            raise Exception(\"Game is over\")\n",
    "        self._move(action)\n",
    "        return self.state, -1, self.done, {}\n",
    "\n",
    "    def _find_end_positions(self, maze):\n",
    "        end_positions = set()\n",
    "        h, w = self.maze.shape\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                if self.maze[i, j] == 2:\n",
    "                    end_positions.add((i, j))\n",
    "                    self.maze[i, j] = 0\n",
    "        return end_positions\n",
    "    \n",
    "    def _move(self, action):\n",
    "        i, j = self.state\n",
    "        h, w = self.maze.shape\n",
    "        if action == 0:   # UP\n",
    "            i = max(0, i - 1)\n",
    "        elif action == 1: # DOWN\n",
    "            i = min(h - 1, i + 1)\n",
    "        elif action == 2: # LEFT\n",
    "            j = max(0, j - 1)\n",
    "        elif action == 3: # RIGHT\n",
    "            j = min(w - 1, j + 1)\n",
    "        if self.maze[i, j] == 0:\n",
    "            self.state = (i, j)\n",
    "    \n",
    "    def render_state(self, zoom: int):\n",
    "        h, w = self.maze.shape\n",
    "        m = np.zeros((h, w, 3), 'uint8')\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                if self.maze[i, j] == 1:\n",
    "                    m[i, j, 0] = 255\n",
    "        for i, j in self.end_positions:\n",
    "            m[i, j, 1] = 255\n",
    "        i, j = self.state\n",
    "        m[i, j, 2] = 255\n",
    "        image = Image.fromarray(m, 'RGB')\n",
    "        image = image.resize((w * zoom, h * zoom))\n",
    "        return image        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionValues(abc.ABC):    \n",
    "    @abc.abstractmethod\n",
    "    def get_action_value(self, state, action) -> float:\n",
    "        pass\n",
    "    \n",
    "    def get_best_action(self, state, actions):\n",
    "        best_action = None\n",
    "        best_score = float('-inf')\n",
    "        for action in actions:\n",
    "            score = self.get_action_value(state, action)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_action = action\n",
    "        return best_action\n",
    "\n",
    "\n",
    "class DiscreteActionValues(ActionValues):\n",
    "    def __init__(self,default_value: float = 0., learning_rate: float = 0.1):\n",
    "        # The default value might help in early exploration (if set in a higher value than what can possibly be)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.values = defaultdict(lambda: defaultdict(lambda: default_value))\n",
    "    \n",
    "    def add(self, state, action, score: float) -> float:\n",
    "        self.values[state][action] += self.learning_rate * (score - self.values[state][action])\n",
    "    \n",
    "    def get_action_value(self, state, action) -> float:\n",
    "        return self.values[state][action]\n",
    "\n",
    "    \n",
    "class SumOfActionValues(ActionValues):\n",
    "    def __init__(self, action_values: List[ActionValues]):\n",
    "        self.action_values = action_values\n",
    "    \n",
    "    def get_action_value(self, state, action) -> float:\n",
    "        return sum(vals.get_action_value(state, action) for vals in self.action_values)\n",
    "    \n",
    "\n",
    "class SARSA:\n",
    "    def __init__(self,\n",
    "                 default_value: float = 0.,\n",
    "                 learning_rate: float = 0.1,\n",
    "                 reward_discount: float = 1.,\n",
    "                 epsilon: float = 0.1):\n",
    "        self.q_values = DiscreteActionValues(default_value=default_value, learning_rate=learning_rate)\n",
    "        self.reward_discount = reward_discount\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def play_episode(self, env) -> float:\n",
    "        total_reward = 0.\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = self._behavior_policy_action(env, state)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            new_action = self._target_policy_action(env, new_state)\n",
    "            score = reward + self.reward_discount * self.q_values.get_action_value(new_state, new_action)\n",
    "            self.q_values.add(state, action, score)\n",
    "            total_reward += reward\n",
    "            state = new_state\n",
    "        return total_reward\n",
    "    \n",
    "    def get_action(self, env, state):\n",
    "        return self._target_policy_action(env, state)\n",
    "    \n",
    "    def _target_policy_action(self, env, state):\n",
    "        return self._behavior_policy_action(env, state)\n",
    "    \n",
    "    def _behavior_policy_action(self, env, state):\n",
    "        if self.epsilon > 0. and np.random.random() < self.epsilon:\n",
    "            return env.action_space.sample()\n",
    "        return self.q_values.get_best_action(state, range(env.action_space.n))\n",
    "\n",
    "\n",
    "class QLearning(SARSA):\n",
    "    def __init__(self,\n",
    "                 default_value: float = 0.,\n",
    "                 learning_rate: float = 0.1,\n",
    "                 reward_discount: float = 1.,\n",
    "                 epsilon: float = 0.1):\n",
    "        super().__init__(default_value=default_value, learning_rate=learning_rate, reward_discount=reward_discount, epsilon=epsilon)\n",
    "    \n",
    "    def _target_policy_action(self, env, state):\n",
    "        return self.q_values.get_best_action(state, range(env.action_space.n))\n",
    "    \n",
    "\n",
    "class DoubleQLearning:\n",
    "    def __init__(self,\n",
    "                 default_value: float = 0.,\n",
    "                 learning_rate: float = 0.1,\n",
    "                 reward_discount: float = 1.,\n",
    "                 epsilon: float = 0.1):\n",
    "        self.q_values = [\n",
    "            DiscreteActionValues(default_value=default_value, learning_rate=learning_rate),\n",
    "            DiscreteActionValues(default_value=default_value, learning_rate=learning_rate)]\n",
    "        self.q_values_sum = SumOfActionValues(self.q_values)\n",
    "        self.reward_discount = reward_discount\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def play_episode(self, env) -> float:\n",
    "        total_reward = 0.\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            action = self._behavior_policy_action(env, state)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            which_q = np.random.randint(0, 2)\n",
    "            q1 = self.q_values[which_q]\n",
    "            q2 = self.q_values[1-which_q]\n",
    "            new_action = q1.get_best_action(new_state, range(env.action_space.n))\n",
    "            score = reward + self.reward_discount * q2.get_action_value(new_state, new_action)\n",
    "            q2.add(state, action, score)\n",
    "            \n",
    "            total_reward += reward\n",
    "            state = new_state\n",
    "        return total_reward\n",
    "    \n",
    "    def get_action(self, env, state):\n",
    "        return self.q_values_sum.get_best_action(state, range(env.action_space.n))\n",
    "    \n",
    "    def _behavior_policy_action(self, env, state):\n",
    "        if self.epsilon > 0. and np.random.random() < self.epsilon:\n",
    "            return env.action_space.sample()\n",
    "        return self.q_values_sum.get_best_action(state, range(env.action_space.n))\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Training Loop\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class RunningAverage:\n",
    "    def __init__(self):\n",
    "        self.average = 0.\n",
    "        self.count = 0\n",
    "    \n",
    "    def add(self, value):\n",
    "        self.average += 1 / (self.count + 1) * (value - self.average)\n",
    "        self.count += 1\n",
    "    \n",
    "    def reset(self):\n",
    "        average = self.average\n",
    "        self.average = 0.\n",
    "        self.count = 0\n",
    "        return average\n",
    "    \n",
    "    def get(self):\n",
    "        return self.average\n",
    "\n",
    "\n",
    "def train_agent(env, agent, nb_episodes: int):\n",
    "    episodes = []\n",
    "    averages = []\n",
    "    running_average = RunningAverage()\n",
    "    temperature_decrease_period = nb_episodes // 21\n",
    "    temperature_decrease = agent.epsilon / 20\n",
    "    for episode in range(1, nb_episodes + 1):\n",
    "        reward = agent.play_episode(env)\n",
    "        running_average.add(reward)\n",
    "        if episode % temperature_decrease_period == 0:\n",
    "            episodes.append(episode)\n",
    "            averages.append(running_average.reset())\n",
    "            print(\"Episode\", episode, \":\", averages[-1], \" (epsilon \" + str(agent.epsilon) + \")\")\n",
    "            agent.epsilon -= temperature_decrease\n",
    "    return episodes, averages\n",
    "\n",
    "\n",
    "def demo_agent(env, agent, gif_name: str):\n",
    "    images = []\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.get_action(env, state)\n",
    "        images.append(env.render_state(10))\n",
    "        state, reward, done, info = env.step(action)\n",
    "    images.append(env.render_state(10))\n",
    "    imageio.mimsave(gif_name, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 23 : -616.6956521739131  (epsilon 0.1)\n",
      "Episode 46 : -303.695652173913  (epsilon 0.095)\n",
      "Episode 69 : -219.86956521739128  (epsilon 0.09)\n",
      "Episode 92 : -177.69565217391303  (epsilon 0.08499999999999999)\n",
      "Episode 115 : -144.0434782608696  (epsilon 0.07999999999999999)\n",
      "Episode 138 : -121.95652173913042  (epsilon 0.07499999999999998)\n",
      "Episode 161 : -105.08695652173913  (epsilon 0.06999999999999998)\n",
      "Episode 184 : -94.30434782608695  (epsilon 0.06499999999999997)\n",
      "Episode 207 : -82.21739130434783  (epsilon 0.05999999999999998)\n",
      "Episode 230 : -75.08695652173913  (epsilon 0.05499999999999998)\n",
      "Episode 253 : -67.5217391304348  (epsilon 0.04999999999999998)\n",
      "Episode 276 : -61.91304347826085  (epsilon 0.044999999999999984)\n",
      "Episode 299 : -56.913043478260875  (epsilon 0.03999999999999999)\n",
      "Episode 322 : -51.69565217391303  (epsilon 0.03499999999999999)\n",
      "Episode 345 : -49.30434782608695  (epsilon 0.02999999999999999)\n",
      "Episode 368 : -45.695652173913054  (epsilon 0.024999999999999988)\n",
      "Episode 391 : -44.21739130434782  (epsilon 0.019999999999999987)\n",
      "Episode 414 : -42.43478260869565  (epsilon 0.014999999999999986)\n",
      "Episode 437 : -41.52173913043478  (epsilon 0.009999999999999985)\n",
      "Episode 460 : -40.13043478260869  (epsilon 0.0049999999999999845)\n",
      "Episode 483 : -39.21739130434783  (epsilon -1.5612511283791264e-17)\n",
      "--------------------------------------------------\n",
      "Episode 23 : -622.1304347826087  (epsilon 0.1)\n",
      "Episode 46 : -300.3043478260869  (epsilon 0.095)\n",
      "Episode 69 : -217.304347826087  (epsilon 0.09)\n",
      "Episode 92 : -175.34782608695653  (epsilon 0.08499999999999999)\n",
      "Episode 115 : -143.91304347826085  (epsilon 0.07999999999999999)\n",
      "Episode 138 : -123.73913043478261  (epsilon 0.07499999999999998)\n",
      "Episode 161 : -104.86956521739131  (epsilon 0.06999999999999998)\n",
      "Episode 184 : -93.78260869565216  (epsilon 0.06499999999999997)\n",
      "Episode 207 : -83.78260869565219  (epsilon 0.05999999999999998)\n",
      "Episode 230 : -73.95652173913042  (epsilon 0.05499999999999998)\n",
      "Episode 253 : -66.30434782608694  (epsilon 0.04999999999999998)\n",
      "Episode 276 : -62.17391304347826  (epsilon 0.044999999999999984)\n",
      "Episode 299 : -55.95652173913043  (epsilon 0.03999999999999999)\n",
      "Episode 322 : -52.43478260869565  (epsilon 0.03499999999999999)\n",
      "Episode 345 : -48.69565217391305  (epsilon 0.02999999999999999)\n",
      "Episode 368 : -46.2608695652174  (epsilon 0.024999999999999988)\n",
      "Episode 391 : -43.82608695652173  (epsilon 0.019999999999999987)\n",
      "Episode 414 : -42.1304347826087  (epsilon 0.014999999999999986)\n",
      "Episode 437 : -41.565217391304344  (epsilon 0.009999999999999985)\n",
      "Episode 460 : -39.95652173913044  (epsilon 0.0049999999999999845)\n",
      "Episode 483 : -39.73913043478261  (epsilon -1.5612511283791264e-17)\n",
      "--------------------------------------------------\n",
      "Episode 47 : -646.8297872340428  (epsilon 0.1)\n",
      "Episode 94 : -294.3829787234043  (epsilon 0.095)\n",
      "Episode 141 : -198.97872340425533  (epsilon 0.09)\n",
      "Episode 188 : -164.76595744680847  (epsilon 0.08499999999999999)\n",
      "Episode 235 : -137.40425531914897  (epsilon 0.07999999999999999)\n",
      "Episode 282 : -123.63829787234042  (epsilon 0.07499999999999998)\n",
      "Episode 329 : -105.19148936170212  (epsilon 0.06999999999999998)\n",
      "Episode 376 : -93.10638297872342  (epsilon 0.06499999999999997)\n",
      "Episode 423 : -84.10638297872339  (epsilon 0.05999999999999998)\n",
      "Episode 470 : -71.59574468085111  (epsilon 0.05499999999999998)\n",
      "Episode 517 : -63.31914893617021  (epsilon 0.04999999999999998)\n",
      "Episode 564 : -55.59574468085106  (epsilon 0.044999999999999984)\n",
      "Episode 611 : -47.659574468085104  (epsilon 0.03999999999999999)\n",
      "Episode 658 : -47.021276595744695  (epsilon 0.03499999999999999)\n",
      "Episode 705 : -42.87234042553192  (epsilon 0.02999999999999999)\n",
      "Episode 752 : -39.93617021276595  (epsilon 0.024999999999999988)\n",
      "Episode 799 : -40.10638297872341  (epsilon 0.019999999999999987)\n",
      "Episode 846 : -39.829787234042556  (epsilon 0.014999999999999986)\n",
      "Episode 893 : -39.46808510638298  (epsilon 0.009999999999999985)\n",
      "Episode 940 : -39.255319148936174  (epsilon 0.0049999999999999845)\n",
      "Episode 987 : -39.0  (epsilon -1.5612511283791264e-17)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "maze = MazeEnv(\n",
    "    maze=np.array([[0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                   [0, 1, 0, 1, 0, 1, 1, 0, 1],\n",
    "                   [0, 1, 1, 1, 0, 1, 0, 0, 0],\n",
    "                   [0, 0, 0, 1, 0, 1, 1, 1, 0],\n",
    "                   [1, 1, 0, 1, 0, 0, 1, 0, 0],\n",
    "                   [0, 1, 0, 1, 1, 0, 1, 0, 1],\n",
    "                   [0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
    "                   [1, 0, 1, 1, 0, 1, 1, 1, 0],\n",
    "                   [0, 0, 0, 0, 0, 0, 1, 2, 0]]),\n",
    "    start_pos=(0, 0)\n",
    ")\n",
    "\n",
    "sarsa = SARSA(default_value = 0., learning_rate = 0.1, reward_discount = 1., epsilon = 0.1)\n",
    "episodes, averages = train_agent(env=maze, agent=sarsa, nb_episodes=500)\n",
    "plt.plot(episodes, averages)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "qlearning = QLearning(default_value = 0., learning_rate = 0.1, reward_discount = 1., epsilon = 0.1)\n",
    "episodes, averages = train_agent(env=maze, agent=qlearning, nb_episodes=500)\n",
    "plt.plot(episodes, averages)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "double_q = DoubleQLearning(default_value = 0., learning_rate = 0.1, reward_discount = 1., epsilon = 0.1)\n",
    "episodes, averages = train_agent(env=maze, agent=double_q, nb_episodes=1000)\n",
    "plt.plot(episodes, averages)\n",
    "\n",
    "plt.show()\n",
    "demo_agent(maze, sarsa, gif_name='6_maze_sarsa.gif')\n",
    "demo_agent(maze, qlearning, gif_name='6_maze_qlearning.gif')\n",
    "demo_agent(maze, double_q, gif_name='6_maze_double_q.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "from collections import *\n",
    "from dataclasses import dataclass\n",
    "import enum\n",
    "import gym\n",
    "import numpy as np\n",
    "from typing import *\n",
    "\n",
    "%matplotlib inline\n",
    "import imageio\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pyglet\n",
    "from pyglet.gl import *\n",
    "\n",
    "window = pyglet.window.Window(width=300, height=200, display=None)\n",
    "window.clear()\n",
    "\n",
    "from gym.envs.classic_control import rendering\n",
    "viewer = rendering.Viewer(screen_width, screen_height)\n",
    "'''\n",
    "\n",
    "# TODO - complexe... first without the maze, find the place to go\n",
    "\n",
    "# TODO - move through a maze where 1 are blocked, 0 are free, and you must find the end\n",
    "# TODO - use convolution net to find the right decision\n",
    "# TODO - reward is -1 for each time your are in the maze\n",
    "\n",
    "# TODO - make a custom space for actions / states?\n",
    "\n",
    "\n",
    "class MazeEnv(gym.Env):\n",
    "    def __init__(self, maze: np.ndarray, start_pos: Tuple[int, int]):\n",
    "        self.maze: np.ndarray = np.array(maze)\n",
    "        self.start_pos: Tuple[int, int] = start_pos\n",
    "        self.end_positions: Set[Tuple[int, int]] = self._find_end_positions(maze)\n",
    "        self.state = None # Must be immutable? I guess so\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        self.observation_space = gym.spaces.MultiDiscrete(list(maze.shape))\n",
    "    \n",
    "    @property\n",
    "    def done(self) -> bool:\n",
    "        return self.state in self.end_positions\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = self.start_pos\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, action):\n",
    "        if self.done:\n",
    "            raise Exception(\"Game is over\")\n",
    "        self._move(action)\n",
    "        return self.state, -1, self.done, {}\n",
    "\n",
    "    def _find_end_positions(self, maze):\n",
    "        end_positions = set()\n",
    "        h, w = self.maze.shape\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                if self.maze[i, j] == 2:\n",
    "                    end_positions.add((i, j))\n",
    "                    self.maze[i, j] = 0\n",
    "        return end_positions\n",
    "    \n",
    "    def _move(self, action):\n",
    "        i, j = self.state\n",
    "        h, w = self.maze.shape\n",
    "        if action == 0:   # UP\n",
    "            i = max(0, i - 1)\n",
    "        elif action == 1: # DOWN\n",
    "            i = min(h - 1, i + 1)\n",
    "        elif action == 2: # LEFT\n",
    "            j = max(0, j - 1)\n",
    "        elif action == 3: # RIGHT\n",
    "            j = min(w - 1, j + 1)\n",
    "        if self.maze[i, j] == 0:\n",
    "            self.state = (i, j)\n",
    "    \n",
    "    def render_state(self, zoom: int):\n",
    "        h, w = self.maze.shape\n",
    "        m = np.zeros((h, w, 3), 'uint8')\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                if self.maze[i, j] == 1:\n",
    "                    m[i, j, 0] = 255\n",
    "        for i, j in self.end_positions:\n",
    "            m[i, j, 1] = 255\n",
    "        i, j = self.state\n",
    "        m[i, j, 2] = 255\n",
    "        image = Image.fromarray(m, 'RGB')\n",
    "        image = image.resize((w * zoom, h * zoom))\n",
    "        return image        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionValues(abc.ABC):    \n",
    "    @abc.abstractmethod\n",
    "    def get_action_value(self, state, action) -> float:\n",
    "        pass\n",
    "    \n",
    "    def get_best_action(self, state, actions):\n",
    "        best_action = None\n",
    "        best_score = float('-inf')\n",
    "        for action in actions:\n",
    "            score = self.get_action_value(state, action)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_action = action\n",
    "        return best_action\n",
    "\n",
    "\n",
    "class DiscreteActionValues(ActionValues):\n",
    "    def __init__(self,default_value: float = 0., learning_rate: float = 0.1):\n",
    "        # The default value might help in early exploration (if set in a higher value than what can possibly be)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.values = defaultdict(lambda: defaultdict(lambda: default_value))\n",
    "    \n",
    "    def add(self, state, action, score: float) -> float:\n",
    "        self.values[state][action] += self.learning_rate * (score - self.values[state][action])\n",
    "    \n",
    "    def get_action_value(self, state, action) -> float:\n",
    "        return self.values[state][action]\n",
    "\n",
    "    \n",
    "class SumOfActionValues(ActionValues):\n",
    "    def __init__(self, action_values: List[ActionValues]):\n",
    "        self.action_values = action_values\n",
    "    \n",
    "    def get_action_value(self, state, action) -> float:\n",
    "        return sum(vals.get_action_value(state, action) for vals in self.action_values)\n",
    "    \n",
    "\n",
    "class SARSA:\n",
    "    def __init__(self,\n",
    "                 default_value: float = 0.,\n",
    "                 learning_rate: float = 0.1,\n",
    "                 reward_discount: float = 1.,\n",
    "                 epsilon: float = 0.1):\n",
    "        self.q_values = DiscreteActionValues(default_value=default_value, learning_rate=learning_rate)\n",
    "        self.reward_discount = reward_discount\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def play_episode(self, env) -> float:\n",
    "        total_reward = 0.\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = self._behavior_policy_action(env, state)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            new_action = self._target_policy_action(env, new_state)\n",
    "            score = reward + self.reward_discount * self.q_values.get_action_value(new_state, new_action)\n",
    "            self.q_values.add(state, action, score)\n",
    "            total_reward += reward\n",
    "            state = new_state\n",
    "        return total_reward\n",
    "    \n",
    "    def get_action(self, env, state):\n",
    "        return self._target_policy_action(env, state)\n",
    "    \n",
    "    def _target_policy_action(self, env, state):\n",
    "        return self._behavior_policy_action(env, state)\n",
    "    \n",
    "    def _behavior_policy_action(self, env, state):\n",
    "        if self.epsilon > 0. and np.random.random() < self.epsilon:\n",
    "            return env.action_space.sample()\n",
    "        return self.q_values.get_best_action(state, range(env.action_space.n))\n",
    "\n",
    "\n",
    "class QLearning(SARSA):\n",
    "    def __init__(self,\n",
    "                 default_value: float = 0.,\n",
    "                 learning_rate: float = 0.1,\n",
    "                 reward_discount: float = 1.,\n",
    "                 epsilon: float = 0.1):\n",
    "        super().__init__(default_value=default_value, learning_rate=learning_rate, reward_discount=reward_discount, epsilon=epsilon)\n",
    "    \n",
    "    def _target_policy_action(self, env, state):\n",
    "        return self.q_values.get_best_action(state, range(env.action_space.n))\n",
    "    \n",
    "\n",
    "class DoubleQLearning:\n",
    "    def __init__(self,\n",
    "                 default_value: float = 0.,\n",
    "                 learning_rate: float = 0.1,\n",
    "                 reward_discount: float = 1.,\n",
    "                 epsilon: float = 0.1):\n",
    "        self.q_values = [\n",
    "            DiscreteActionValues(default_value=default_value, learning_rate=learning_rate),\n",
    "            DiscreteActionValues(default_value=default_value, learning_rate=learning_rate)]\n",
    "        self.q_values_sum = SumOfActionValues(self.q_values)\n",
    "        self.reward_discount = reward_discount\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def play_episode(self, env) -> float:\n",
    "        total_reward = 0.\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            action = self._behavior_policy_action(env, state)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            which_q = np.random.randint(0, 2)\n",
    "            q1, q2 = self.q_values[which_q], self.q_values[1-which_q]\n",
    "            new_action = q2.get_best_action(new_state, range(env.action_space.n))\n",
    "            q2.add(state, action, reward + self.reward_discount * q1.get_action_value(new_state, new_action))\n",
    "            \n",
    "            total_reward += reward\n",
    "            state = new_state\n",
    "        return total_reward\n",
    "    \n",
    "    def get_action(self, env, state):\n",
    "        return self.q_values_sum.get_best_action(state, range(env.action_space.n))\n",
    "    \n",
    "    def _behavior_policy_action(self, env, state):\n",
    "        if self.epsilon > 0. and np.random.random() < self.epsilon:\n",
    "            return env.action_space.sample()\n",
    "        return self.q_values_sum.get_best_action(state, range(env.action_space.n))\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Training Loop\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class RunningAverage:\n",
    "    def __init__(self):\n",
    "        self.average = 0.\n",
    "        self.count = 0\n",
    "    \n",
    "    def add(self, value):\n",
    "        self.average += 1 / (self.count + 1) * (value - self.average)\n",
    "        self.count += 1\n",
    "    \n",
    "    def reset(self):\n",
    "        average = self.average\n",
    "        self.average = 0.\n",
    "        self.count = 0\n",
    "        return average\n",
    "    \n",
    "    def get(self):\n",
    "        return self.average\n",
    "\n",
    "\n",
    "def train_agent(env, agent, nb_episodes: int):\n",
    "    episodes = []\n",
    "    averages = []\n",
    "    running_average = RunningAverage()\n",
    "    temperature_decrease_period = nb_episodes // 21\n",
    "    temperature_decrease = agent.epsilon / 20\n",
    "    for episode in range(1, nb_episodes + 1):\n",
    "        reward = agent.play_episode(env)\n",
    "        running_average.add(reward)\n",
    "        if episode % temperature_decrease_period == 0:\n",
    "            episodes.append(episode)\n",
    "            averages.append(running_average.reset())\n",
    "            print(\"Episode\", episode, \":\", averages[-1], \" (epsilon \" + str(agent.epsilon) + \")\")\n",
    "            agent.epsilon -= temperature_decrease\n",
    "    return episodes, averages\n",
    "\n",
    "\n",
    "def demo_agent(env, agent, gif_name: str):\n",
    "    images = []\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.get_action(env, state)\n",
    "        images.append(env.render_state(10))\n",
    "        state, reward, done, info = env.step(action)\n",
    "    images.append(env.render_state(10))\n",
    "    imageio.mimsave(gif_name, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 23 : -623.304347826087  (epsilon 0.1)\n",
      "Episode 46 : -300.82608695652175  (epsilon 0.095)\n",
      "Episode 69 : -221.08695652173915  (epsilon 0.09)\n",
      "Episode 92 : -173.95652173913044  (epsilon 0.08499999999999999)\n",
      "Episode 115 : -141.2173913043478  (epsilon 0.07999999999999999)\n",
      "Episode 138 : -122.65217391304348  (epsilon 0.07499999999999998)\n",
      "Episode 161 : -106.60869565217394  (epsilon 0.06999999999999998)\n",
      "Episode 184 : -94.60869565217392  (epsilon 0.06499999999999997)\n",
      "Episode 207 : -83.2608695652174  (epsilon 0.05999999999999998)\n",
      "Episode 230 : -74.08695652173914  (epsilon 0.05499999999999998)\n",
      "Episode 253 : -69.04347826086956  (epsilon 0.04999999999999998)\n",
      "Episode 276 : -61.869565217391305  (epsilon 0.044999999999999984)\n",
      "Episode 299 : -56.30434782608697  (epsilon 0.03999999999999999)\n",
      "Episode 322 : -52.52173913043478  (epsilon 0.03499999999999999)\n",
      "Episode 345 : -48.95652173913044  (epsilon 0.02999999999999999)\n",
      "Episode 368 : -47.173913043478265  (epsilon 0.024999999999999988)\n",
      "Episode 391 : -43.82608695652174  (epsilon 0.019999999999999987)\n",
      "Episode 414 : -42.69565217391305  (epsilon 0.014999999999999986)\n",
      "Episode 437 : -40.69565217391304  (epsilon 0.009999999999999985)\n",
      "Episode 460 : -40.1304347826087  (epsilon 0.0049999999999999845)\n",
      "Episode 483 : -39.78260869565217  (epsilon -1.5612511283791264e-17)\n",
      "--------------------------------------------------\n",
      "Episode 23 : -619.8260869565216  (epsilon 0.1)\n",
      "Episode 46 : -302.5217391304348  (epsilon 0.095)\n",
      "Episode 69 : -219.65217391304344  (epsilon 0.09)\n",
      "Episode 92 : -175.65217391304353  (epsilon 0.08499999999999999)\n",
      "Episode 115 : -143.69565217391303  (epsilon 0.07999999999999999)\n",
      "Episode 138 : -121.69565217391303  (epsilon 0.07499999999999998)\n",
      "Episode 161 : -106.8695652173913  (epsilon 0.06999999999999998)\n",
      "Episode 184 : -92.65217391304346  (epsilon 0.06499999999999997)\n",
      "Episode 207 : -83.00000000000003  (epsilon 0.05999999999999998)\n",
      "Episode 230 : -73.8695652173913  (epsilon 0.05499999999999998)\n",
      "Episode 253 : -68.6086956521739  (epsilon 0.04999999999999998)\n",
      "Episode 276 : -60.52173913043479  (epsilon 0.044999999999999984)\n",
      "Episode 299 : -55.65217391304348  (epsilon 0.03999999999999999)\n",
      "Episode 322 : -52.13043478260868  (epsilon 0.03499999999999999)\n",
      "Episode 345 : -48.869565217391305  (epsilon 0.02999999999999999)\n",
      "Episode 368 : -45.869565217391305  (epsilon 0.024999999999999988)\n",
      "Episode 391 : -44.21739130434782  (epsilon 0.019999999999999987)\n",
      "Episode 414 : -42.0  (epsilon 0.014999999999999986)\n",
      "Episode 437 : -40.56521739130435  (epsilon 0.009999999999999985)\n",
      "Episode 460 : -40.086956521739125  (epsilon 0.0049999999999999845)\n",
      "Episode 483 : -39.869565217391305  (epsilon -1.5612511283791264e-17)\n",
      "--------------------------------------------------\n",
      "Episode 47 : -647.2553191489362  (epsilon 0.1)\n",
      "Episode 94 : -302.2340425531915  (epsilon 0.095)\n",
      "Episode 141 : -232.04255319148936  (epsilon 0.09)\n",
      "Episode 188 : -180.00000000000003  (epsilon 0.08499999999999999)\n",
      "Episode 235 : -144.78723404255317  (epsilon 0.07999999999999999)\n",
      "Episode 282 : -126.04255319148936  (epsilon 0.07499999999999998)\n",
      "Episode 329 : -116.82978723404257  (epsilon 0.06999999999999998)\n",
      "Episode 376 : -108.12765957446808  (epsilon 0.06499999999999997)\n",
      "Episode 423 : -89.10638297872342  (epsilon 0.05999999999999998)\n",
      "Episode 470 : -76.57446808510639  (epsilon 0.05499999999999998)\n",
      "Episode 517 : -64.46808510638297  (epsilon 0.04999999999999998)\n",
      "Episode 564 : -54.06382978723404  (epsilon 0.044999999999999984)\n",
      "Episode 611 : -47.78723404255319  (epsilon 0.03999999999999999)\n",
      "Episode 658 : -43.53191489361703  (epsilon 0.03499999999999999)\n",
      "Episode 705 : -42.19148936170213  (epsilon 0.02999999999999999)\n",
      "Episode 752 : -40.319148936170215  (epsilon 0.024999999999999988)\n",
      "Episode 799 : -39.80851063829787  (epsilon 0.019999999999999987)\n",
      "Episode 846 : -39.659574468085104  (epsilon 0.014999999999999986)\n",
      "Episode 893 : -39.319148936170215  (epsilon 0.009999999999999985)\n",
      "Episode 940 : -39.234042553191486  (epsilon 0.0049999999999999845)\n",
      "Episode 987 : -39.0  (epsilon -1.5612511283791264e-17)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "maze = MazeEnv(\n",
    "    maze=np.array([[0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                   [0, 1, 0, 1, 0, 1, 1, 0, 1],\n",
    "                   [0, 1, 1, 1, 0, 1, 0, 0, 0],\n",
    "                   [0, 0, 0, 1, 0, 1, 1, 1, 0],\n",
    "                   [1, 1, 0, 1, 0, 0, 1, 0, 0],\n",
    "                   [0, 1, 0, 1, 1, 0, 1, 0, 1],\n",
    "                   [0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
    "                   [1, 0, 1, 1, 0, 1, 1, 1, 0],\n",
    "                   [0, 0, 0, 0, 0, 0, 1, 2, 0]]),\n",
    "    start_pos=(0, 0)\n",
    ")\n",
    "\n",
    "sarsa = SARSA(default_value = 0., learning_rate = 0.1, reward_discount = 1., epsilon = 0.1)\n",
    "episodes, averages = train_agent(env=maze, agent=sarsa, nb_episodes=500)\n",
    "plt.plot(episodes, averages)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "qlearning = QLearning(default_value = 0., learning_rate = 0.1, reward_discount = 1., epsilon = 0.1)\n",
    "episodes, averages = train_agent(env=maze, agent=qlearning, nb_episodes=500)\n",
    "plt.plot(episodes, averages)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "double_q = DoubleQLearning(default_value = 0., learning_rate = 0.1, reward_discount = 1., epsilon = 0.1)\n",
    "episodes, averages = train_agent(env=maze, agent=double_q, nb_episodes=1000)\n",
    "plt.plot(episodes, averages)\n",
    "\n",
    "plt.show()\n",
    "demo_agent(maze, sarsa, gif_name='6_maze_sarsa.gif')\n",
    "demo_agent(maze, qlearning, gif_name='6_maze_qlearning.gif')\n",
    "demo_agent(maze, double_q, gif_name='6_maze_double_q.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
